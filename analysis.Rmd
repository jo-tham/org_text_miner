# Get required packages

```{r, eval=FALSE}
## library(devtools)
## install.packages('tm')
## install.packages("SnowballC")
## devtools::install_github("cran/wordcloud")
## help(package="tm")
```

# Setup corpus

- At this point I became frustrated with the CamlCase
  inconsistencies

```{r}
suppressPackageStartupMessages(library(tm))
project_dir <- "~/projects/9999-99-99_master_text_miner"
setwd(project_dir)
org_dir <- "~/projects/9999-99-99_master_text_miner/data"
org_dir_source <- DirSource(org_dir)
agenda_corpus <- VCorpus(x=org_dir_source,
                         readerControl=
                             list(reader = reader(org_dir_source),
                                  language = "en"))
```

# Inspect the corpus

- Structure of the corpus object

```{r}
typeof(agenda_corpus)
str(agenda_corpus[1])
```

```{r, eval=FALSE}
inspect(agenda_corpus[c(1, 4, 5)])
```

# Tranformations and filtering
- It is important to remove some content, such as
  punctuation, letter case, certain words, etc.
- what transformations are available?

```{r}
getTransformations()
```

- Makes sense, except stem.
  [What's that?](http://en.wikipedia.org/wiki/Stemming). Oh,
  so reduce a compound or derivative words to their base.
  So, e.g. "computing", "computers", "computation", etc may
  be identified as "compute". Not a great example, since
  compute and computer are rather different. Digress.
- Undigress, that highlights that one should be familiar
  with the stemming algorithm. I'll assume it's OK for this
  exercise.

```{r, results='hold'}
suppressPackageStartupMessages(library(SnowballC))
lapply(agenda_corpus, nchar)
agenda_corpus <- tm_map(agenda_corpus,
                        content_transformer(removeWords),
                        stopwords())
#lapply(agenda_corpus, nchar)
agenda_corpus <- tm_map(agenda_corpus,
                        content_transformer(removePunctuation))
#lapply(agenda_corpus, nchar)
agenda_corpus <- tm_map(agenda_corpus,
                        content_transformer(removeNumbers))
#lapply(agenda_corpus, nchar)
agenda_corpus <- tm_map(agenda_corpus,
                        content_transformer(stripWhitespace))
#lapply(agenda_corpus, nchar)
agenda_corpus <- tm_map(agenda_corpus,
                        content_transformer(stemDocument))
lapply(agenda_corpus, nchar)
```

- future project, pertaining to org specifically, is add
  custom transformations, e.g.

# Create document term matrix
- Here's how to imagine a document term matrix
 doc      | word1  | word2 | ... | wordN 
--------- | -------|-------|-----|-------
 doc1.txt | freq11 | freq12| ... | freq1N
 doc2.txt | freq21 | freq22| ... | freq2N
    .     |   .    |    .  |  .  |   .   
    .     |   .    |    .  |  .  |   .   
    .     |   .    |    .  |  .  |   .   
 docn.txt | freqn1 | freqn2| ... | freqnN

```{r}
org_doc_term_matrix <- DocumentTermMatrix(agenda_corpus)
str(org_doc_term_matrix)
inspect(org_doc_term_matrix[, 1:10])
```
- hmm, would be nice to see most frequent terms.

# Examine document term matrix

```{r}
org_term_freq <- colSums(as.matrix(org_doc_term_matrix))
org_term_order <- order(org_term_freq)
names(org_term_freq[tail(org_term_order, n=25L)])
```
- the org mode todo items are common. Blimey, ive done a lot.
- It might be intersting to remove them, but it also
  indicates the actionability of my work. Identify tasks and
  execute.
- more examining reveals many other semi-useless words in
  top 50+ words

```{r}
findFreqTerms(org_doc_term_matrix, lowfreq=1000)
findFreqTerms(org_doc_term_matrix, lowfreq=100)
findFreqTerms(org_doc_term_matrix, lowfreq=10)
```

```{r}
bulk_terms <- findFreqTerms(org_doc_term_matrix, lowfreq=175)
agenda_corpus_xbulk <- tm_map(agenda_corpus,
                              content_transformer(removeWords),
                              bulk_terms, lazy = FALSE)
lapply(agenda_corpus, nchar)
lapply(agenda_corpus_xbulk, nchar)
org_doc_term_matrix_xbulk <- DocumentTermMatrix(agenda_corpus_xbulk)
org_term_freq_xbulk <- colSums(as.matrix(org_doc_term_matrix_xbulk))
findFreqTerms(org_doc_term_matrix_xbulk, lowfreq = 100)
```
- can also examine word associations, plot associations,
  which I will omit here.

# Plot wordcloud

- I had issues isntalling wordcloud. Github worked, my cran
  mirror (Rstudio) didn't.

```{r}
library("wordcloud")
# set seed so cloud layout fixed
set.seed(1945)
par(mfrow=c(2,1))
wordcloud(names(org_term_freq), org_term_freq,
          min.freq=40,
          colors=brewer.pal(6,"Dark2"))
wordcloud(names(org_term_freq_xbulk), org_term_freq_xbulk,
          min.freq=40,
          colors=brewer.pal(6,"Dark2"))
```

# References
- http://onepager.togaware.com/TextMiningO.pdf
- http://cran.r-project.org/web/packages/tm/vignettes/tm.pdf
- 
