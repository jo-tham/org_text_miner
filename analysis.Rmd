---
output:
  md_document:
    variant: markdown_github
---

# Get required packages

```{r, eval=FALSE}
library(devtools)
install.packages('tm')
install.packages("SnowballC")
devtools::install_github("cran/wordcloud")
```

# Setup corpus

- Around here I became frustrated with the CamlCase
  inconsistencies. Oh well.
- The recursive argument doesn't seem to work, either.
  Something to investigate.

```{r}
suppressPackageStartupMessages(library(tm))
project_dir <- "~/projects/9999-99-99_master_text_miner"
setwd(project_dir)
org_dir <- "~/projects/9999-99-99_master_text_miner/data"
org_dir_source <- DirSource(org_dir, recursive = FALSE)
agenda_corpus <- VCorpus(x=org_dir_source,
                         readerControl=
                             list(reader = reader(org_dir_source),
                                  language = "en"))
```

# Inspect the corpus

- Structure of the corpus object

```{r, results='hold'}
typeof(agenda_corpus)
str(agenda_corpus[1])
```

```{r, eval=FALSE}
inspect(agenda_corpus[c(1, 4, 5)])
```

# Tranformations and filtering
- It is important to remove some content, such as
  punctuation, letter case, certain words, etc.
- what transformations are available?

```{r}
getTransformations()
```

- Makes sense, except stem.
  [What's that?](http://en.wikipedia.org/wiki/Stemming). Oh,
  so reduce a compound or derivative words to their base.
  So, e.g. "computing", "computers", "computation", etc may
  be identified as "compute". Not a great example, since
  compute and computer are rather different. Digress.
- Undigress, that highlights that one should be familiar
  with the stemming algorithm. I'll assume it's OK for this
  exercise.

```{r, results='hold'}
suppressPackageStartupMessages(library(SnowballC))
lapply(agenda_corpus, nchar)[[1]]
agenda_corpus <- tm_map(agenda_corpus,
                        content_transformer(removeWords),
                        stopwords())
agenda_corpus <- tm_map(agenda_corpus,
                        content_transformer(removePunctuation))
agenda_corpus <- tm_map(agenda_corpus,
                        content_transformer(removeNumbers))
agenda_corpus <- tm_map(agenda_corpus,
                        content_transformer(stripWhitespace))
agenda_corpus <- tm_map(agenda_corpus,
                        content_transformer(stemDocument))
lapply(agenda_corpus, nchar)[[1]]
```
- the transformations working, but removeWords with the org
  agenda terms wasn't working. A hack is implemented below
  for wordcloud.
- future project, pertaining to org specifically, is add
  custom transformations, e.g. DONE, TODO, NEXT etc

# Create document term matrix
- Here's how to imagine a document term matrix

doc       | word1  | word2 | ... | wordN 
--------- | -------|-------|-----|-------
 doc1.txt | freq11 | freq12| ... | freq1N
 doc2.txt | freq21 | freq22| ... | freq2N
   ....   |   ...  | ..... | ... | ..... 
 docn.txt | freqn1 | freqn2| ... | freqnN


```{r, results='hold'}
org_doc_term_matrix <- DocumentTermMatrix(agenda_corpus)
str(org_doc_term_matrix)
inspect(org_doc_term_matrix[, 1:10])
```

- hmm, would be nice to see most frequent terms.

# Examine document term matrix

```{r}
org_term_freq <- colSums(as.matrix(org_doc_term_matrix))
org_term_order <- order(org_term_freq)
org_term_freq[tail(org_term_order, n=25L)]
```

- the org mode todo items are common. Blimey, ive done a lot.
- It might be intersting to remove them, but it also
  indicates the actionability of my work. Identify tasks and
  execute.
- more examining reveals many other semi-useless words in
  top 50+ words

```{r}
findFreqTerms(org_doc_term_matrix, lowfreq=1000)
findFreqTerms(org_doc_term_matrix, lowfreq=100)
```

- can also examine word associations, plot associations,
  which I will omit here.

# Plot wordcloud

- I had issues isntalling wordcloud. Github worked, my cran
  mirror (Rstudio) didn't.
- There's a hack in here to plot only some of the words,
  since omitting the org bulk words via removeWords didn't
  work. I heard there's a bug with removeWords if they're at the
  start of a line, which the org state words usually are.

```{r, warning=FALSE}
library("wordcloud")
set.seed(1945)
wordcloud(names(org_term_freq), org_term_freq,
          min.freq=40,
          colors=brewer.pal(6,"Dark2"))
org_term_freq[tail(org_term_order, n=25L)]
all_terms <- length(org_term_freq)
omit_last <- 25
wordcloud(names(org_term_freq[head(org_term_order,
                                   n=all_terms-omit_last)]),
          org_term_freq[head(org_term_order,
                             n=all_terms-omit_last)],
          min.freq=15,
          colors=brewer.pal(5,"Dark2"))
```

# Finally, make wordclouds for individual org agenda files

- I've omitted some of the plots for brevity.

```{r, warning=FALSE, results='hold'}
setwd("data")
org_dirs <- dir()[!grepl(".org",dir())]
org_dirs
corp_to_wordcloud <- function(top_dir){
    dir_source <- DirSource(top_dir)
    agenda_corpus <- VCorpus(x=dir_source,
                             readerControl=
                                 list(reader = reader(dir_source),
                                      language = "en"))
    agenda_corpus <- tm_map(agenda_corpus,
                            content_transformer(removeWords),
                            stopwords())
    agenda_corpus <- tm_map(agenda_corpus,
                            content_transformer(removePunctuation))
    agenda_corpus <- tm_map(agenda_corpus,
                            content_transformer(removeNumbers))
    agenda_corpus <- tm_map(agenda_corpus,
                            content_transformer(stripWhitespace))
    agenda_corpus <- tm_map(agenda_corpus,
                            content_transformer(stemDocument))
    org_doc_term_matrix <- DocumentTermMatrix(agenda_corpus)
    org_term_freq <- colSums(as.matrix(org_doc_term_matrix))
    org_term_order <- order(org_term_freq)
    set.seed(1945)
    all_terms <- length(org_term_freq)
    omit_last <- 15
    wordcloud(names(org_term_freq[head(org_term_order,
                                       n=all_terms-omit_last)]),
              org_term_freq[head(org_term_order,
                                 n=all_terms-omit_last)],
              min.freq=15,
              colors=brewer.pal(5,"Dark2"), main=dir_source)
}
lapply(org_dirs, corp_to_wordcloud)

```

# Next time
- Try python's nltk
- I think some normalization of the word frequencies against
  a null case (some generic books, dictionary, i don't know
  what) might be more interesting
- Trim terms using in inflection points on the ordered terms
  vs frequency relationship
- Animate the wordclouds of the individual org agenda files

# References
- http://onepager.togaware.com/TextMiningO.pdf
- http://cran.r-project.org/web/packages/tm/vignettes/tm.pdf
